{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Introduction\n",
    "\n",
    "## Part 1\n",
    "The following code loads the olympics dataset (olympics.csv), which was derrived from the Wikipedia entry on [All Time Olympic Games Medals](https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table), and does some basic data cleaning. \n",
    "\n",
    "The columns are organized as # of Summer games, Summer medals, # of Winter games, Winter medals, total # number of games, total # of medals. Use this dataset to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Summer</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Bronze</th>\n",
       "      <th>Total</th>\n",
       "      <th># Winter</th>\n",
       "      <th>Gold.1</th>\n",
       "      <th>Silver.1</th>\n",
       "      <th>Bronze.1</th>\n",
       "      <th>Total.1</th>\n",
       "      <th># Games</th>\n",
       "      <th>Gold.2</th>\n",
       "      <th>Silver.2</th>\n",
       "      <th>Bronze.2</th>\n",
       "      <th>Combined total</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>ALG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>ARG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Armenia</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>ARM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australasia</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>ANZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             # Summer  Gold  Silver  Bronze  Total  # Winter  Gold.1  \\\n",
       "Afghanistan        13     0       0       2      2         0       0   \n",
       "Algeria            12     5       2       8     15         3       0   \n",
       "Argentina          23    18      24      28     70        18       0   \n",
       "Armenia             5     1       2       9     12         6       0   \n",
       "Australasia         2     3       4       5     12         0       0   \n",
       "\n",
       "             Silver.1  Bronze.1  Total.1  # Games  Gold.2  Silver.2  Bronze.2  \\\n",
       "Afghanistan         0         0        0       13       0         0         2   \n",
       "Algeria             0         0        0       15       5         2         8   \n",
       "Argentina           0         0        0       41      18        24        28   \n",
       "Armenia             0         0        0       11       1         2         9   \n",
       "Australasia         0         0        0        2       3         4         5   \n",
       "\n",
       "             Combined total   ID  \n",
       "Afghanistan               2  AFG  \n",
       "Algeria                  15  ALG  \n",
       "Argentina                70  ARG  \n",
       "Armenia                  12  ARM  \n",
       "Australasia              12  ANZ  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./data/olympics.csv', index_col=0, skiprows=1)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col[:2]=='01':\n",
    "        df.rename(columns={col:'Gold'+col[4:]}, inplace=True)\n",
    "    if col[:2]=='02':\n",
    "        df.rename(columns={col:'Silver'+col[4:]}, inplace=True)\n",
    "    if col[:2]=='03':\n",
    "        df.rename(columns={col:'Bronze'+col[4:]}, inplace=True)\n",
    "    if col[:1]=='â„–':\n",
    "        df.rename(columns={col:'#'+col[1:]}, inplace=True)\n",
    "\n",
    "names_ids = df.index.str.split('\\s\\(') # split the index by '('\n",
    "\n",
    "df.index = names_ids.str[0] # the [0] element is the country name (new index) \n",
    "df['ID'] = names_ids.str[1].str[:3] # the [1] element is the abbreviation or ID (take first 3 characters from that)\n",
    "\n",
    "df = df.drop('Totals')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Which country has won the most gold medals in summer games?\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country with most gold medals during summer games: United States.\n"
     ]
    }
   ],
   "source": [
    "def answer_one():\n",
    "    \"\"\"\n",
    "    Return the name of the country which has won the most\n",
    "    gold medals during the summer games.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy['Country'] = df_copy.index\n",
    "    df_copy.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    return df_copy.loc[df_copy['Gold'].idxmax()]['Country']\n",
    "print('Country with most gold medals during summer games: {}.'.format(answer_one()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Which country had the biggest difference between their summer and winter gold medal counts?\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country with biggest difference between summer and winter gold medal counts: United States.\n"
     ]
    }
   ],
   "source": [
    "def answer_two():\n",
    "    \"\"\"\n",
    "    Country with the biggest difference between their\n",
    "    summer and winter gold medal counts\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy['Country'] = df_copy.index\n",
    "    df_copy.reset_index(inplace=True,drop=True)\n",
    "    df_copy['Diff'] = df_copy['Gold'] - df_copy['Gold.1']\n",
    "    \n",
    "    return df_copy.loc[df_copy['Diff'].idxmax()]['Country']\n",
    "print('Country with biggest difference between summer and winter gold medal counts: {}.'.format(answer_two()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Which country has the biggest difference between their summer gold medal counts and winter gold medal counts relative to their total gold medal count? \n",
    "\n",
    "$$\\frac{Summer~Gold - Winter~Gold}{Total~Gold}$$\n",
    "\n",
    "Only include countries that have won at least 1 gold in both summer and winter.\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country with largest summer to winter gold medal counts: Bulgaria.\n"
     ]
    }
   ],
   "source": [
    "def answer_three():\n",
    "    \"\"\"\n",
    "    Country with biggest ratio.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy['Country'] = df_copy.index\n",
    "    df_copy.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    mask = (df_copy['Gold']>=1) & (df_copy['Gold.1']>=1)\n",
    "    df_copy = df_copy[mask]\n",
    "    \n",
    "    df_copy['Diff'] = (df_copy['Gold'] - df_copy['Gold.1']) / df_copy['Gold.2']\n",
    "\n",
    "    \n",
    "    return df_copy.loc[df_copy['Diff'].idxmax()]['Country']\n",
    "print('Country with largest summer to winter gold medal counts: {}.'.format(answer_three()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Write a function that creates a Series called \"Points\" which is a weighted value where each gold medal (`Gold.2`) counts for 3 points, silver medals (`Silver.2`) for 2 points, and bronze medals (`Bronze.2`) for 1 point. The function should return only the column (a Series object) which you created, with the country names as indices.\n",
    "\n",
    "*This function should return a Series named `Points` of length 146*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Afghanistan      2\n",
       "Algeria         29\n",
       "Argentina      154\n",
       "Armenia         18\n",
       "Australasia     26\n",
       "Name: Points, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    points = df['Gold.2']*3+df['Silver.2']*3+df['Bronze.2']\n",
    "    points.name='Points'\n",
    "    return points\n",
    "answer_four()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "For the next set of questions, we will be using census data from the [United States Census Bureau](http://www.census.gov). Counties are political and geographic subdivisions of states in the United States. This dataset contains population data for counties and states in the US from 2010 to 2015. [See this document](https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2015/co-est2015-alldata.pdf) for a description of the variable names.\n",
    "\n",
    "The census dataset (census.csv) should be loaded as census_df. Answer questions using this as appropriate.\n",
    "\n",
    "### Question 5\n",
    "Which state has the most counties in it? (hint: consider the sumlevel key carefully! You'll need this for future questions too...)\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>ESTIMATESBASE2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2011</th>\n",
       "      <th>RDOMESTICMIG2012</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4779736</td>\n",
       "      <td>4780127</td>\n",
       "      <td>4785161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>-0.193196</td>\n",
       "      <td>0.381066</td>\n",
       "      <td>0.582002</td>\n",
       "      <td>-0.467369</td>\n",
       "      <td>1.030015</td>\n",
       "      <td>0.826644</td>\n",
       "      <td>1.383282</td>\n",
       "      <td>1.724718</td>\n",
       "      <td>0.712594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242091</td>\n",
       "      <td>-2.915927</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>...</td>\n",
       "      <td>14.832960</td>\n",
       "      <td>17.647293</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.728132</td>\n",
       "      <td>-2.500690</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.527043</td>\n",
       "      <td>-5.068871</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUMLEV  REGION  DIVISION  STATE  COUNTY   STNAME         CTYNAME  \\\n",
       "0      40       3         6      1       0  Alabama         Alabama   \n",
       "1      50       3         6      1       1  Alabama  Autauga County   \n",
       "2      50       3         6      1       3  Alabama  Baldwin County   \n",
       "3      50       3         6      1       5  Alabama  Barbour County   \n",
       "4      50       3         6      1       7  Alabama     Bibb County   \n",
       "\n",
       "   CENSUS2010POP  ESTIMATESBASE2010  POPESTIMATE2010  ...  RDOMESTICMIG2011  \\\n",
       "0        4779736            4780127          4785161  ...          0.002295   \n",
       "1          54571              54571            54660  ...          7.242091   \n",
       "2         182265             182265           183193  ...         14.832960   \n",
       "3          27457              27457            27341  ...         -4.728132   \n",
       "4          22915              22919            22861  ...         -5.527043   \n",
       "\n",
       "   RDOMESTICMIG2012  RDOMESTICMIG2013  RDOMESTICMIG2014  RDOMESTICMIG2015  \\\n",
       "0         -0.193196          0.381066          0.582002         -0.467369   \n",
       "1         -2.915927         -3.012349          2.265971         -2.530799   \n",
       "2         17.647293         21.845705         19.243287         17.197872   \n",
       "3         -2.500690         -7.056824         -3.904217        -10.543299   \n",
       "4         -5.068871         -6.201001         -0.177537          0.177258   \n",
       "\n",
       "   RNETMIG2011  RNETMIG2012  RNETMIG2013  RNETMIG2014  RNETMIG2015  \n",
       "0     1.030015     0.826644     1.383282     1.724718     0.712594  \n",
       "1     7.606016    -2.626146    -2.722002     2.592270    -2.187333  \n",
       "2    15.844176    18.559627    22.727626    20.317142    18.293499  \n",
       "3    -4.874741    -2.758113    -7.167664    -3.978583   -10.543299  \n",
       "4    -5.088389    -4.363636    -5.403729     0.754533     1.107861  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_df = pd.read_csv('./data/census.csv')\n",
    "census_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The state with the most counties is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Texas'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_five():\n",
    "    \"\"\"\n",
    "    Return state with most counties.\n",
    "    \"\"\"\n",
    "    df = census_df[census_df['SUMLEV']==50]\n",
    "    return df[['STNAME','COUNTY']].groupby('STNAME').count().idxmax().values[0]\n",
    "\n",
    "print('The state with the most counties is:')\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "**Only looking at the three most populous counties for each state**, what are the three most populous states (in order of highest population to lowest population)? Use `CENSUS2010POP`.\n",
    "\n",
    "*This function should return a list of string values.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three most populated states are: California, Texas, and Illinois\n"
     ]
    }
   ],
   "source": [
    "def answer_six():\n",
    "    \"\"\"\n",
    "    Using only the three most populated counties, returns the state with\n",
    "    the highest population count.\n",
    "    \"\"\"\n",
    "    # retrieve only county data\n",
    "    df = census_df[census_df['SUMLEV']==50][['STNAME','CENSUS2010POP']].set_index('STNAME',drop=True)\n",
    "    \n",
    "    df_filtered = pd.DataFrame(columns=['STNAME','POPULATION'])\n",
    "    # find three most populated counties per state\n",
    "    for state in df.index.unique():\n",
    "        if type(df.loc[state,'CENSUS2010POP']) is np.int64:\n",
    "            state_pop = df.loc[state,'CENSUS2010POP']\n",
    "        elif len(df.loc[state,'CENSUS2010POP'])<3:\n",
    "            state_pop = sum(df.loc[state,'CENSUS2010POP'])\n",
    "        else:\n",
    "            state_pop = df.loc[state,'CENSUS2010POP'].sort_values(ascending=False)[0:3].sum()\n",
    "        \n",
    "        df_filtered = df_filtered.append({'STNAME':state,'POPULATION':state_pop},ignore_index=True)\n",
    "    \n",
    "    df_filtered = df_filtered.sort_values(by='POPULATION',ascending=False).head(3)\n",
    "    \n",
    "    # return index\n",
    "    return list(df_filtered['STNAME'].values)\n",
    "\n",
    "print('The three most populated states are: {0}, {1}, and {2}'.format(*answer_six()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Which county has had the largest absolute change in population within the period 2010-2015? (Hint: population values are stored in columns POPESTIMATE2010 through POPESTIMATE2015, you need to consider all six columns.)\n",
    "\n",
    "e.g. If County Population in the 5 year period is 100, 120, 80, 105, 100, 130, then its largest change in the period would be |130-80| = 50.\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The county with the largest absolute change in population within the period 2010-2015 is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Harris County'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_seven():\n",
    "    \"\"\"\n",
    "    Return the county with the largest absolute change in population within the\n",
    "    period 2010-2015.\n",
    "    \"\"\"\n",
    "    df = census_df[census_df['SUMLEV']==50]\n",
    "    df = df.set_index('CTYNAME',drop=True)\n",
    "    \n",
    "    df['Max'] = np.max(df[['POPESTIMATE2010','POPESTIMATE2011',\n",
    "                    'POPESTIMATE2012','POPESTIMATE2013',\n",
    "                    'POPESTIMATE2014','POPESTIMATE2015']],axis=1)\n",
    "    \n",
    "    df['Min'] = np.min(df[['POPESTIMATE2010','POPESTIMATE2011',\n",
    "                    'POPESTIMATE2012','POPESTIMATE2013',\n",
    "                    'POPESTIMATE2014','POPESTIMATE2015']],axis=1)\n",
    "    \n",
    "    df['Change'] = df['Max']-df['Min']\n",
    "    \n",
    "    max_change = df['Change'].idxmax()\n",
    "    \n",
    "    return max_change\n",
    "\n",
    "print('The county with the largest absolute change in population within the period 2010-2015 is:')\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "In this datafile, the United States is broken up into four regions using the \"REGION\" column. \n",
    "\n",
    "Create a query that finds the counties that belong to regions 1 or 2, whose name starts with 'Washington', and whose POPESTIMATE2015 was greater than their POPESTIMATE 2014.\n",
    "\n",
    "*This function should return a 5x2 DataFrame with the columns = ['STNAME', 'CTYNAME'] and the same index ID as the census_df (sorted ascending by index).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            STNAME            CTYNAME\n",
       "896           Iowa  Washington County\n",
       "1419     Minnesota  Washington County\n",
       "2345  Pennsylvania  Washington County\n",
       "2355  Rhode Island  Washington County\n",
       "3163     Wisconsin  Washington County"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eight():\n",
    "    \"\"\"\n",
    "    Return the counties with meet the following requierements:\n",
    "     - belong to region 1 or 2\n",
    "     - name starts with 'W'\n",
    "     - POPESTIMATES > POPESTIMATE2014\n",
    "    \"\"\"\n",
    "    query = (census_df['REGION'].isin([1,2])) & (census_df['CTYNAME'].map(lambda x: x.startswith('Washington'))) & (census_df['POPESTIMATE2015'] > census_df['POPESTIMATE2014'])\n",
    "    \n",
    "    df = census_df[query]\n",
    "    \n",
    "    return df[['STNAME', 'CTYNAME']].sort_index()\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Pandas\n",
    "This assignment requires more individual learning then the last one did - you are encouraged to check out the [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/) to find functions or methods you might not have used yet, or ask questions on [Stack Overflow](http://stackoverflow.com/) and tag them as pandas and python related. And of course, the discussion forums are open for interaction with your peers and the course staff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (20%)\n",
    "Load the energy data from the file `Energy Indicators.xls`, which is a list of indicators of [energy supply and renewable electricity production](Energy%20Indicators.xls) from the [United Nations](http://unstats.un.org/unsd/environment/excel_file_tables/2013/Energy%20Indicators.xls) for the year 2013, and should be put into a DataFrame with the variable name of **energy**.\n",
    "\n",
    "Keep in mind that this is an Excel file, and not a comma separated values file. Also, make sure to exclude the footer and header information from the datafile. The first two columns are unneccessary, so you should get rid of them, and you should change the column labels so that the columns are:\n",
    "\n",
    "`['Country', 'Energy Supply', 'Energy Supply per Capita', '% Renewable']`\n",
    "\n",
    "Convert `Energy Supply` to gigajoules (there are 1,000,000 gigajoules in a petajoule). For all countries which have missing data (e.g. data with \"...\") make sure this is reflected as `np.NaN` values.\n",
    "\n",
    "Rename the following list of countries (for use in later questions):\n",
    "\n",
    "```\"Republic of Korea\": \"South Korea\",\n",
    "\"United States of America\": \"United States\",\n",
    "\"United Kingdom of Great Britain and Northern Ireland\": \"United Kingdom\",\n",
    "\"China, Hong Kong Special Administrative Region\": \"Hong Kong\"```\n",
    "\n",
    "There are also several countries with numbers and/or parenthesis in their name. Be sure to remove these, \n",
    "\n",
    "e.g. \n",
    "\n",
    "`'Bolivia (Plurinational State of)'` should be `'Bolivia'`, \n",
    "\n",
    "`'Switzerland17'` should be `'Switzerland'`.\n",
    "\n",
    "<br>\n",
    "\n",
    "Next, load the GDP data from the file `world_bank.csv`, which is a csv containing countries' GDP from 1960 to 2015 from [World Bank](http://data.worldbank.org/indicator/NY.GDP.MKTP.CD). Call this DataFrame **GDP**. \n",
    "\n",
    "Make sure to skip the header, and rename the following list of countries:\n",
    "\n",
    "```\"Korea, Rep.\": \"South Korea\", \n",
    "\"Iran, Islamic Rep.\": \"Iran\",\n",
    "\"Hong Kong SAR, China\": \"Hong Kong\"```\n",
    "\n",
    "<br>\n",
    "\n",
    "Finally, load the [Sciamgo Journal and Country Rank data for Energy Engineering and Power Technology](http://www.scimagojr.com/countryrank.php?category=2102) from the file `scimagojr-3.xlsx`, which ranks countries based on their journal contributions in the aforementioned area. Call this DataFrame **ScimEn**.\n",
    "\n",
    "Join the three datasets: GDP, Energy, and ScimEn into a new dataset (using the intersection of country names). Use only the last 10 years (2006-2015) of GDP data and only the top 15 countries by Scimagojr 'Rank' (Rank 1 through 15). \n",
    "\n",
    "The index of this DataFrame should be the name of the country, and the columns should be ['Rank', 'Documents', 'Citable documents', 'Citations', 'Self-citations',\n",
    "       'Citations per document', 'H index', 'Energy Supply',\n",
    "       'Energy Supply per Capita', '% Renewable', '2006', '2007', '2008',\n",
    "       '2009', '2010', '2011', '2012', '2013', '2014', '2015'].\n",
    "\n",
    "*This function should return a DataFrame with 20 columns and 15 entries.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ENERGY_FILE = './data/Energy+Indicators.xls'\n",
    "GDP_FILE = './data/world_bank.csv'\n",
    "SCIAMGO_FILE = './data/scimagojr-3.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GDP():\n",
    "    # load gdp data\n",
    "    GDP = pd.read_csv(GDP_FILE,\n",
    "                         skiprows=4)\n",
    "    \n",
    "    # rename column\n",
    "    GDP = GDP.rename(columns={'Country Name':'Country'})\n",
    "    \n",
    "    # rename countries\n",
    "    GDP['Country'] = GDP['Country'].str.replace('Korea, Rep.', 'South Korea')\n",
    "    GDP['Country'] = GDP['Country'].str.replace('Iran, Islamic Rep.', 'Iran')\n",
    "    GDP['Country'] = GDP['Country'].str.replace('Hong Kong SAR, China', 'Hong Kong')\n",
    "\n",
    "    # filter dataframe before merge:\n",
    "    # last 10 years of GDP data\n",
    "    GDP  = GDP[['Country','2006','2007','2008','2009',\n",
    "               '2010','2011','2012','2013','2014','2015']]\n",
    "    \n",
    "    return GDP\n",
    "\n",
    "def get_energy():\n",
    "    # load energy incidators files\n",
    "    energy = pd.read_excel(ENERGY_FILE,\n",
    "                       skiprows=17,\n",
    "                       skipfooter=38,\n",
    "                       usecols=[2,3,4,5,6],\n",
    "                       index_col=0,\n",
    "                       na_values='...',\n",
    "                       names = ['Energy Supply', 'Energy Supply per Capita', '% Renewable'])\n",
    "    \n",
    "    # reset index\n",
    "    energy.index.name = 'Country'\n",
    "    energy = energy.reset_index()\n",
    "    \n",
    "    # convert supply\n",
    "    energy['Energy Supply'] = energy['Energy Supply'] * 10**6\n",
    "    \n",
    "    # remove digits in index\n",
    "    energy['Country'] = energy['Country'].str.replace(\"\\d+\", \"\")\n",
    "    \n",
    "    # remove (...) from index\n",
    "    energy['Country'] = energy['Country'].str.split(' \\(').str[0].str.strip()\n",
    "    \n",
    "    # rename countries\n",
    "    energy['Country'] = energy['Country'].str.replace('Republic of Korea','South Korea')\n",
    "    energy['Country'] = energy['Country'].str.replace('United States of America','United States')\n",
    "    energy['Country'] = energy['Country'].str.replace('United Kingdom of Great Britain and Northern Ireland','United Kingdom')\n",
    "    energy['Country'] = energy['Country'].str.replace('China, Hong Kong Special Administrative Region','Hong Kong')\n",
    "    \n",
    "    return energy\n",
    "\n",
    "def get_ScimEn():\n",
    "    # load scimago file\n",
    "    ScimEn = pd.read_excel(SCIAMGO_FILE)\n",
    "    \n",
    "    return ScimEn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    \n",
    "    # load data\n",
    "    energy, GDP, ScimEn = get_energy(), get_GDP(), get_ScimEn()\n",
    "        \n",
    "    # Join the three datasets: GDP, Energy, and ScimEn into a new dataset (using the intersection of country names).\n",
    "    df_merge = pd.merge(left=GDP,right=energy,\n",
    "                        how='inner',left_on='Country',\n",
    "                        right_on='Country')\n",
    "    df_merge = pd.merge(left=df_merge,right=ScimEn,\n",
    "                        how='inner',left_on='Country',\n",
    "                        right_on='Country')\n",
    "    \n",
    "    # filter to only maintain the country with a Rank <= 15\n",
    "    df_merge = df_merge[df_merge['Rank']<=15]\n",
    "    \n",
    "    df_merge = df_merge.set_index('Country',drop=True)\n",
    "    \n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (6.6%)\n",
    "The previous question joined three datasets then reduced this to just the top 15 entries. When you joined the datasets, but before you reduced this to the top 15 items, how many entries did you lose?\n",
    "\n",
    "*This function should return a single number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg width=\"800\" height=\"300\">\n",
       "  <circle cx=\"150\" cy=\"180\" r=\"80\" fill-opacity=\"0.2\" stroke=\"black\" stroke-width=\"2\" fill=\"blue\" />\n",
       "  <circle cx=\"200\" cy=\"100\" r=\"80\" fill-opacity=\"0.2\" stroke=\"black\" stroke-width=\"2\" fill=\"red\" />\n",
       "  <circle cx=\"100\" cy=\"100\" r=\"80\" fill-opacity=\"0.2\" stroke=\"black\" stroke-width=\"2\" fill=\"green\" />\n",
       "  <line x1=\"150\" y1=\"125\" x2=\"300\" y2=\"150\" stroke=\"black\" stroke-width=\"2\" fill=\"black\" stroke-dasharray=\"5,3\"/>\n",
       "  <text  x=\"300\" y=\"165\" font-family=\"Verdana\" font-size=\"35\">Everything but this!</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<svg width=\"800\" height=\"300\">\n",
    "  <circle cx=\"150\" cy=\"180\" r=\"80\" fill-opacity=\"0.2\" stroke=\"black\" stroke-width=\"2\" fill=\"blue\" />\n",
    "  <circle cx=\"200\" cy=\"100\" r=\"80\" fill-opacity=\"0.2\" stroke=\"black\" stroke-width=\"2\" fill=\"red\" />\n",
    "  <circle cx=\"100\" cy=\"100\" r=\"80\" fill-opacity=\"0.2\" stroke=\"black\" stroke-width=\"2\" fill=\"green\" />\n",
    "  <line x1=\"150\" y1=\"125\" x2=\"300\" y2=\"150\" stroke=\"black\" stroke-width=\"2\" fill=\"black\" stroke-dasharray=\"5,3\"/>\n",
    "  <text  x=\"300\" y=\"165\" font-family=\"Verdana\" font-size=\"35\">Everything but this!</text>\n",
    "</svg>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    # load data\n",
    "    energy, GDP, ScimEn = get_energy(), get_GDP(), get_ScimEn()\n",
    "    \n",
    "    tdf_in = pd.merge(left=GDP, right=energy, on='Country',how='inner')\n",
    "    tdf_in = pd.merge(left=tdf_in, right=ScimEn, on='Country',how='inner')\n",
    "    \n",
    "    tdf_out = pd.merge(left=GDP, right=energy, on='Country',how='outer')\n",
    "    tdf_out = pd.merge(left=tdf_out, right=ScimEn, on='Country',how='outer')\n",
    "\n",
    "    return len(tdf_out) - len(tdf_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer the following questions in the context of only the top 15 countries by Scimagojr Rank (aka the DataFrame returned by `answer_one()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (6.6%)\n",
    "What is the average GDP over the last 10 years for each country? (exclude missing values from this calculation.)\n",
    "\n",
    "*This function should return a Series named `avgGDP` with 15 countries and their average GDP sorted in descending order.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    Top15 = answer_one()\n",
    "    \n",
    "    years = [str(x) for x in range(2006,2016)]\n",
    "    results = Top15[years].mean(axis=1).sort_values(ascending=False)\n",
    "    results.name = 'avgGDP'\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (6.6%)\n",
    "By how much had the GDP changed over the 10 year span for the country with the 6th largest average GDP?\n",
    "\n",
    "*This function should return a single number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_four():\n",
    "    # load data\n",
    "    Top15 = answer_one()\n",
    "    \n",
    "    # find 6th largest GDP\n",
    "    sixth_gdp = answer_three().sort_values(ascending=False).iloc[5]\n",
    "    sixth_country = answer_three()[answer_three()==sixth_gdp].index[0]\n",
    "    \n",
    "    return Top15.loc[sixth_country,'2015'] - Top15.loc[sixth_country,'2006']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (6.6%)\n",
    "What is the mean `Energy Supply per Capita`?\n",
    "\n",
    "*This function should return a single number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_five():\n",
    "    Top15 = answer_one()\n",
    "    return Top15['Energy Supply per Capita'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 (6.6%)\n",
    "What country has the maximum % Renewable and what is the percentage?\n",
    "\n",
    "*This function should return a tuple with the name of the country and the percentage.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_six():\n",
    "    Top15 = answer_one()\n",
    "    return (Top15['% Renewable'].idxmax(),Top15['% Renewable'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 (6.6%)\n",
    "Create a new column that is the ratio of Self-Citations to Total Citations. \n",
    "What is the maximum value for this new column, and what country has the highest ratio?\n",
    "\n",
    "*This function should return a tuple with the name of the country and the ratio.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    Top15 = answer_one()\n",
    "    Top15['Ratio'] = Top15['Self-citations'] / Top15['Citations']\n",
    "    return (Top15['Ratio'].idxmax(),Top15['Ratio'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 (6.6%)\n",
    "\n",
    "Create a column that estimates the population using Energy Supply and Energy Supply per capita. \n",
    "What is the third most populous country according to this estimate?\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_eight():\n",
    "    Top15 = answer_one()\n",
    "    Top15['Pop'] = Top15['Energy Supply'] / Top15['Energy Supply per Capita']\n",
    "    return Top15['Pop'].nlargest(3).iloc[[-1]].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 (6.6%)\n",
    "Create a column that estimates the number of citable documents per person. \n",
    "What is the correlation between the number of citable documents per capita and the energy supply per capita? Use the `.corr()` method, (Pearson's correlation).\n",
    "\n",
    "*This function should return a single number.*\n",
    "\n",
    "*(Optional: Use the built-in function `plot9()` to visualize the relationship between Energy Supply per Capita vs. Citable docs per Capita)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_nine():\n",
    "    Top15 = answer_one()\n",
    "    Top15['PopEst'] = Top15['Energy Supply'] / Top15['Energy Supply per Capita']\n",
    "    Top15['Citable docs per Capita'] = Top15['Citable documents'] / Top15['PopEst']\n",
    "    \n",
    "    corr = Top15[['Citable docs per Capita','Energy Supply per Capita']].corr()\n",
    "    corr = corr.loc['Energy Supply per Capita', 'Citable docs per Capita']\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot9():\n",
    "    import matplotlib as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    Top15 = answer_one()\n",
    "    Top15['PopEst'] = Top15['Energy Supply'] / Top15['Energy Supply per Capita']\n",
    "    Top15['Citable docs per Capita'] = Top15['Citable documents'] / Top15['PopEst']\n",
    "    Top15.plot(x='Citable docs per Capita', y='Energy Supply per Capita', kind='scatter', xlim=[0, 0.0006])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10 (6.6%)\n",
    "Create a new column with a 1 if the country's % Renewable value is at or above the median for all countries in the top 15, and a 0 if the country's % Renewable value is below the median.\n",
    "\n",
    "*This function should return a series named `HighRenew` whose index is the country name sorted in ascending order of rank.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_ten():\n",
    "    Top15 = answer_one()\n",
    "    Top15['Median'] = Top15['% Renewable']>=Top15['% Renewable'].median()\n",
    "    Top15['Median'] = Top15['Median'].astype(float)\n",
    "    HighRenew = Top15.loc[:,['Rank','Median']].sort_values('Rank',ascending=True)\n",
    "    HighRenew = HighRenew['Median']\n",
    "    HighRenew.name = 'HighRenew'\n",
    "    return HighRenew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11 (6.6%)\n",
    "Use the following dictionary to group the Countries by Continent, then create a dateframe that displays the sample size (the number of countries in each continent bin), and the sum, mean, and std deviation for the estimated population of each country.\n",
    "\n",
    "```python\n",
    "ContinentDict  = {'China':'Asia', \n",
    "                  'United States':'North America', \n",
    "                  'Japan':'Asia', \n",
    "                  'United Kingdom':'Europe', \n",
    "                  'Russian Federation':'Europe', \n",
    "                  'Canada':'North America', \n",
    "                  'Germany':'Europe', \n",
    "                  'India':'Asia',\n",
    "                  'France':'Europe', \n",
    "                  'South Korea':'Asia', \n",
    "                  'Italy':'Europe', \n",
    "                  'Spain':'Europe', \n",
    "                  'Iran':'Asia',\n",
    "                  'Australia':'Australia', \n",
    "                  'Brazil':'South America'}\n",
    "```\n",
    "\n",
    "*This function should return a DataFrame with index named Continent `['Asia', 'Australia', 'Europe', 'North America', 'South America']` and columns `['size', 'sum', 'mean', 'std']`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ContinentDict  = {'China':'Asia', \n",
    "              'United States':'North America', \n",
    "              'Japan':'Asia', \n",
    "              'United Kingdom':'Europe', \n",
    "              'Russian Federation':'Europe', \n",
    "              'Canada':'North America', \n",
    "              'Germany':'Europe', \n",
    "              'India':'Asia',\n",
    "              'France':'Europe', \n",
    "              'South Korea':'Asia', \n",
    "              'Italy':'Europe', \n",
    "              'Spain':'Europe', \n",
    "              'Iran':'Asia',\n",
    "              'Australia':'Australia', \n",
    "              'Brazil':'South America'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_eleven():\n",
    "    Top15 = answer_one()\n",
    "    Top15['Continent'] = Top15.index\n",
    "    \n",
    "    Top15['Continent'] = Top15['Continent'].apply(lambda x: ContinentDict[x])\n",
    "    Top15['PopEst'] = Top15['Energy Supply'] / Top15['Energy Supply per Capita']\n",
    "    Top15 = Top15.groupby('Continent')['PopEst'].agg({'size': np.size, 'sum': np.sum, 'mean': np.average, 'std': np.std})\n",
    "    \n",
    "    return Top15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12 (6.6%)\n",
    "Cut % Renewable into 5 bins. Group Top15 by the Continent, as well as these new % Renewable bins. How many countries are in each of these groups?\n",
    "\n",
    "*This function should return a __Series__ with a MultiIndex of `Continent`, then the bins for `% Renewable`. Do not include groups with no countries.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_twelve():\n",
    "    Top15 = answer_one()\n",
    "    Top15['Continent'] = Top15.index\n",
    "    Top15['Continent'] = Top15['Continent'].apply(lambda x: ContinentDict[x])\n",
    "    Top15['group'] = pd.cut(Top15['% Renewable'], 5)\n",
    "    Top15 = Top15.groupby(['Continent','group']).size()\n",
    "    \n",
    "    return Top15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13 (6.6%)\n",
    "Convert the Population Estimate series to a string with thousands separator (using commas). Do not round the results.\n",
    "\n",
    "e.g. 317615384.61538464 -> 317,615,384.61538464\n",
    "\n",
    "*This function should return a Series `PopEst` whose index is the country name and whose values are the population estimate string.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_thirteen():\n",
    "    Top15 = answer_one()\n",
    "    Top15['PopEst'] = Top15['Energy Supply'] / Top15['Energy Supply per Capita']\n",
    "    Top15['PopEst'] = Top15['PopEst'].apply(lambda x:'{:,}'.format(x))\n",
    "    return Top15['PopEst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "This assignment requires more individual learning than previous assignments - you are encouraged to check out the [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/) to find functions or methods you might not have used yet, or ask questions on [Stack Overflow](http://stackoverflow.com/) and tag them as pandas and python related. And of course, the discussion forums are open for interaction with your peers and the course staff.\n",
    "\n",
    "Definitions:\n",
    "* A _quarter_ is a specific three month period, Q1 is January through March, Q2 is April through June, Q3 is July through September, Q4 is October through December.\n",
    "* A _recession_ is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
    "* A _recession bottom_ is the quarter within a recession which had the lowest GDP.\n",
    "* A _university town_ is a city which has a high percentage of university students compared to the total population of the city.\n",
    "\n",
    "**Hypothesis**: University towns have their mean housing prices less effected by recessions. Run a t-test to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom. (`price_ratio=quarter_before_recession/recession_bottom`)\n",
    "\n",
    "The following data files are available for this assignment:\n",
    "* From the [Zillow research data site](http://www.zillow.com/research/data/) there is housing data for the United States. In particular the datafile for [all homes at a city level](http://files.zillowstatic.com/research/public/City/City_Zhvi_AllHomes.csv), ```City_Zhvi_AllHomes.csv```, has median home sale prices at a fine grained level.\n",
    "* From the Wikipedia page on college towns is a list of [university towns in the United States](https://en.wikipedia.org/wiki/List_of_college_towns#College_towns_in_the_United_States) which has been copy and pasted into the file ```university_towns.txt```.\n",
    "* From Bureau of Economic Analysis, US Department of Commerce, the [GDP over time](http://www.bea.gov/national/index.htm#gdp) of the United States in current dollars (use the chained value in 2009 dollars), in quarterly intervals, in the file ```gdplev.xls```. For this assignment, only look at GDP data from the first quarter of 2000 onward.\n",
    "\n",
    "Each function in this assignment below is worth 10%, with the exception of ```run_ttest()```, which is worth 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dictionary to map state names to two letter acronyms\n",
    "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_university_towns():\n",
    "    '''Returns a DataFrame of towns and the states they are in from the \n",
    "    university_towns.txt list. The format of the DataFrame should be:\n",
    "    DataFrame( [ [\"Michigan\", \"Ann Arbor\"], [\"Michigan\", \"Yipsilanti\"] ], \n",
    "    columns=[\"State\", \"RegionName\"]  )\n",
    "    \n",
    "    The following cleaning needs to be done:\n",
    "\n",
    "    1. For \"State\", removing characters from \"[\" to the end.\n",
    "    2. For \"RegionName\", when applicable, removing every character from \" (\" to the end.\n",
    "    3. Depending on how you read the data, you may need to remove newline character '\\n'. '''\n",
    "    \n",
    "    # create empty DataFrame\n",
    "    df_towns = pd.DataFrame(columns=[\"State\", \"RegionName\"])\n",
    "    \n",
    "    # file name\n",
    "    file_name = 'university_towns.txt'\n",
    "    \n",
    "    # data extraction\n",
    "    with open(file_name,'r') as f:\n",
    "        state = ''\n",
    "        region = ''\n",
    "        for row in f:\n",
    "            # check if contains state or region\n",
    "            if '[e' in row:\n",
    "                # save state\n",
    "                state = row.split('[ed')[0].strip()\n",
    "                continue\n",
    "            region = row.strip()\n",
    "            if '(' in region:\n",
    "                region = row.split('(')[0].strip()\n",
    "            # populate DataFrame\n",
    "            df_towns = df_towns.append({'State':state,'RegionName':region},ignore_index=True,)        \n",
    "    \n",
    "    return df_towns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gdp_data():\n",
    "    \"\"\" Returns a clean dataframe containing the GDP data per quarter starting in 2000q1\"\"\"\n",
    "    \n",
    "    # file name\n",
    "    file_name = 'gdplev.xls'\n",
    "    \n",
    "    # load quarterly data and clean data\n",
    "    df_gdp = pd.read_excel(file_name,skiprows=5,\n",
    "                           index_col=0,parse_cols=[4,5,6]).dropna()\n",
    "    \n",
    "    index_start = df_gdp.index.get_loc('2000q1')\n",
    "    \n",
    "    # filter data to post 2000\n",
    "    df_gdp = df_gdp.ix[index_start:]\n",
    "    \n",
    "    return df_gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recession_start():\n",
    "    '''Returns the year and quarter of the recession start time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    \n",
    "    # recession dollars\n",
    "    dollars = 'GDP in billions of chained 2009 dollars'\n",
    "    \n",
    "    # load gdp data\n",
    "    df_gdp = get_gdp_data()[dollars]\n",
    "    \n",
    "    # find recession start\n",
    "    for i in range(1,len(df_gdp)-1):\n",
    "        if (df_gdp.iloc[i]<df_gdp.iloc[i-1]) and (df_gdp.iloc[i+1]<df_gdp.iloc[i]):\n",
    "            return df_gdp.index[i]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recession_end():\n",
    "    '''Returns the year and quarter of the recession end time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    \n",
    "    # recession dollars\n",
    "    dollars = 'GDP in billions of chained 2009 dollars'\n",
    "    \n",
    "    # load gdp data\n",
    "    df_gdp = get_gdp_data()[dollars]\n",
    "    \n",
    "    # keep data following recession start\n",
    "    df_gdp = df_gdp.ix[get_recession_start():]\n",
    "    \n",
    "    # find recession end\n",
    "    for i in range(2,len(df_gdp)-1):\n",
    "        if (df_gdp.iloc[i]>df_gdp.iloc[i-1]) and (df_gdp.iloc[i-1]>df_gdp.iloc[i-2]):\n",
    "            return df_gdp.index[i]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recession_bottom():\n",
    "    '''Returns the year and quarter of the recession bottom time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    \n",
    "    # recession dollars\n",
    "    dollars = 'GDP in billions of chained 2009 dollars'\n",
    "    \n",
    "    # load gdp data\n",
    "    df_gdp = get_gdp_data()[dollars]\n",
    "    \n",
    "    # recession starts\n",
    "    start = get_recession_start()\n",
    "    end = get_recession_end()\n",
    "    \n",
    "    # recession data\n",
    "    df_gdp = df_gdp.ix[start:end]\n",
    "    \n",
    "    return df_gdp.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_housing_data():\n",
    "    \"\"\"Return dataframe containing the housing data from Zillow.\"\"\"\n",
    "    \n",
    "    # file name\n",
    "    file_name = 'City_Zhvi_AllHomes.csv'\n",
    "    \n",
    "    # load housing data and clean data\n",
    "    df_housing = (pd.read_csv(file_name)\n",
    "                              .replace(to_replace='NaN', value=np.NaN)\n",
    "                              .convert_objects(convert_numeric=True))\n",
    "    \n",
    "    # remove uneccessary features\n",
    "    df_housing = df_housing.drop(['RegionID', 'Metro', 'CountyName', 'SizeRank'],axis=1)\n",
    "    \n",
    "    # convert state ID to state name\n",
    "    df_housing = df_housing.replace(states)\n",
    "    \n",
    "    # set multi-index\n",
    "    df_housing = df_housing.set_index(['State','RegionName'])\n",
    "        \n",
    "    # filter columns to only contain data starting from 2000\n",
    "    start_col = list(df_housing.columns.values).index('2000-01')\n",
    "    df_housing = df_housing.drop(df_housing.columns[:start_col], axis=1)\n",
    "    \n",
    "    return df_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_housing_data_to_quarters():\n",
    "    '''Converts the housing data to quarters and returns it as mean \n",
    "    values in a dataframe. This dataframe should be a dataframe with\n",
    "    columns for 2000q1 through 2016q3, and should have a multi-index\n",
    "    in the shape of [\"State\",\"RegionName\"].\n",
    "    \n",
    "    Note: Quarters are defined in the assignment description, they are\n",
    "    not arbitrary three month periods.\n",
    "    \n",
    "    The resulting dataframe should have 67 columns, and 10,730 rows.\n",
    "    '''\n",
    "    \n",
    "    # import data\n",
    "    df_housing = get_housing_data().T\n",
    "    \n",
    "    # convert index to time-stamp\n",
    "    df_housing.index = pd.to_datetime(df_housing.index)\n",
    "    \n",
    "    # resample index by quarter and aggregate using mean\n",
    "    df_housing = df_housing.resample('Q').mean()\n",
    "    \n",
    "    # convert index to proper values\n",
    "    df_housing.index = df_housing.index.map(lambda x: str(x.year)+'q'+str((x.month-1)//3+1))\n",
    "    \n",
    "    # transpose data frame\n",
    "    df_housing = df_housing.T\n",
    "    \n",
    "    return df_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ttest():\n",
    "    '''First creates new data showing the decline or growth of housing prices\n",
    "    between the recession start and the recession bottom. Then runs a ttest\n",
    "    comparing the university town values to the non-university towns values, \n",
    "    return whether the alternative hypothesis (that the two groups are the same)\n",
    "    is true or not as well as the p-value of the confidence. \n",
    "    \n",
    "    Return the tuple (different, p, better) where different=True if the t-test is\n",
    "    True at a p<0.01 (we reject the null hypothesis), or different=False if \n",
    "    otherwise (we cannot reject the null hypothesis). The variable p should\n",
    "    be equal to the exact p value returned from scipy.stats.ttest_ind(). The\n",
    "    value for better should be either \"university town\" or \"non-university town\"\n",
    "    depending on which has a lower mean price ratio (which is equivilent to a\n",
    "    reduced market loss).'''\n",
    "    \n",
    "    # load data\n",
    "    df_housing = convert_housing_data_to_quarters()\n",
    "    \n",
    "    # find start and bottom of recession\n",
    "    start_idx = df_housing.columns.get_loc(get_recession_start())\n",
    "    bottom_idx = df_housing.columns.get_loc(get_recession_bottom())\n",
    "    \n",
    "    #(price_ratio=quarter_before_recession/recession_bottom\n",
    "    df_housing['Ratio'] = df_housing[df_housing.columns[start_idx - 1]].div(df_housing[df_housing.columns[bottom_idx]])\n",
    "    \n",
    "    # filter data to relevant feature\n",
    "    df_housing = df_housing[['Ratio']]\n",
    "    \n",
    "    # load univercities cities\n",
    "    df_univ = get_list_of_university_towns().set_index(['State','RegionName'])\n",
    "    \n",
    "    # Univercity cities prices\n",
    "    df_univ_prices = pd.merge(left=df_housing,right=df_univ,how='inner',\n",
    "                            left_index=True,right_index=True)\n",
    "    \n",
    "    # generate non-university cities\n",
    "    non_univ = np.setdiff1d(df_housing.index,df_univ.index)\n",
    "    \n",
    "    # filter data to non-university cities\n",
    "    df_non_univ_prices = df_housing.loc[non_univ]\n",
    "    \n",
    "    # drop Na\n",
    "    df_univ_prices = df_univ_prices.dropna(axis=0)\n",
    "    df_non_univ_prices = df_non_univ_prices.dropna(axis=0)\n",
    "    \n",
    "    # T-test threshold\n",
    "    alpha = 0.01\n",
    "    \n",
    "    # perform T-test\n",
    "    s, p = ttest_ind(df_univ_prices['Ratio'], df_non_univ_prices['Ratio'])\n",
    "    \n",
    "    # assign output variables\n",
    "    different = p<alpha\n",
    "    better = \"university town\" if s<0 else \"non-university town\"\n",
    "    \n",
    "    return (different, p, better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
